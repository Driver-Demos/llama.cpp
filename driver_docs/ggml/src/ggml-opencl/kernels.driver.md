
## Files
- **[add.cl](kernels/add.cl.driver.md)**: The `add.cl` file in the `llama.cpp` codebase contains OpenCL kernels for performing addition on tensors, including support for non-contiguous tensors and broadcasting across specific dimensions.
- **[argsort.cl](kernels/argsort.cl.driver.md)**: The `argsort.cl` file in the `llama.cpp` codebase implements an OpenCL kernel for performing a bitonic sort on floating-point arrays, supporting both ascending and descending order.
- **[clamp.cl](kernels/clamp.cl.driver.md)**: The `clamp.cl` file contains an OpenCL kernel function that clamps the values of a source array to a specified minimum and maximum range, storing the results in a destination array.
- **[concat.cl](kernels/concat.cl.driver.md)**: The `concat.cl` file in the `llama.cpp` codebase contains OpenCL kernels for concatenating two float32 arrays along a specified dimension, handling both contiguous and non-contiguous memory layouts.
- **[cpy.cl](kernels/cpy.cl.driver.md)**: The `cpy.cl` file in the `llama.cpp` codebase contains OpenCL kernels for copying data between buffers with different data types, specifically handling half and float precision formats.
- **[cvt.cl](kernels/cvt.cl.driver.md)**: The `cvt.cl` file in the `llama.cpp` codebase contains OpenCL kernels for data conversion, specifically for converting and restoring `block_q4_0` data structures, with considerations for different GPU architectures.
- **[diag_mask_inf.cl](kernels/diag_mask_inf.cl.driver.md)**: The `diag_mask_inf.cl` file in the `llama.cpp` codebase contains OpenCL kernels for applying a diagonal mask with negative infinity to a matrix, with support for both single and vectorized float operations.
- **[div.cl](kernels/div.cl.driver.md)**: The `div.cl` file in the `llama.cpp` codebase contains OpenCL kernels for performing element-wise division on arrays, including a specialized kernel for dividing a source array by a broadcasted row.
- **[embed_kernel.py](kernels/embed_kernel.py.driver.md)**: The `embed_kernel.py` file in the `llama.cpp` codebase is a script that reads an input file and writes its contents to an output file, wrapping each line in a raw string literal format.
- **[gelu.cl](kernels/gelu.cl.driver.md)**: The `gelu.cl` file in the `llama.cpp` codebase implements OpenCL kernels for the Gaussian Error Linear Unit (GELU) activation function and its quick approximation, supporting both single and vectorized operations.
- **[gemv_noshuffle.cl](kernels/gemv_noshuffle.cl.driver.md)**: The `gemv_noshuffle.cl` file in the `llama.cpp` codebase implements an OpenCL kernel for performing a matrix-vector multiplication without shuffling, utilizing subgroup operations and dequantization techniques for optimized computation on GPUs.
- **[gemv_noshuffle_general.cl](kernels/gemv_noshuffle_general.cl.driver.md)**: The `gemv_noshuffle_general.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for a matrix-vector multiplication operation without shuffling, utilizing subgroup operations and dequantization techniques for performance optimization on GPUs.
- **[get_rows.cl](kernels/get_rows.cl.driver.md)**: The `get_rows.cl` file in the `llama.cpp` codebase contains OpenCL kernels for extracting rows from matrices in different formats, including 32-bit floats, 16-bit floats, and a custom quantized format, with a dequantization function for the latter.
- **[group_norm.cl](kernels/group_norm.cl.driver.md)**: The `group_norm.cl` file in the `llama.cpp` codebase implements an OpenCL kernel for performing group normalization on a set of input data, with support for different GPU architectures and subgroup sizes.
- **[im2col_f16.cl](kernels/im2col_f16.cl.driver.md)**: The `im2col_f16.cl` file contains an OpenCL kernel function `kernel_im2col_f16` that performs the im2col operation on half-precision floating-point data for use in convolutional neural networks.
- **[im2col_f32.cl](kernels/im2col_f32.cl.driver.md)**: The `im2col_f32.cl` file contains an OpenCL kernel function for transforming image data into column format, which is commonly used in convolution operations.
- **[mul.cl](kernels/mul.cl.driver.md)**: The `mul.cl` file in the `llama.cpp` codebase contains OpenCL kernels for performing element-wise multiplication on arrays, including a specialized kernel for broadcasting a row vector across another array.
- **[mul_mat_Ab_Bi_8x4.cl](kernels/mul_mat_Ab_Bi_8x4.cl.driver.md)**: The `mul_mat_Ab_Bi_8x4.cl` file in the `llama.cpp` codebase contains an OpenCL kernel for performing matrix multiplication on 8x4 tiles using quantized weights and scales, optimized for certain GPU architectures.
- **[mul_mv_f16_f16.cl](kernels/mul_mv_f16_f16.cl.driver.md)**: The `mul_mv_f16_f16.cl` file in the `llama.cpp` codebase contains an OpenCL kernel for performing matrix-vector multiplication using half-precision floating-point numbers, with optimizations for different GPU architectures.
- **[mul_mv_f16_f32.cl](kernels/mul_mv_f16_f32.cl.driver.md)**: The `mul_mv_f16_f32.cl` file in the `llama.cpp` codebase contains an OpenCL kernel for performing matrix-vector multiplication with mixed precision, using half-precision (f16) for the matrix and single-precision (f32) for the vector.
- **[mul_mv_f16_f32_1row.cl](kernels/mul_mv_f16_f32_1row.cl.driver.md)**: The `mul_mv_f16_f32_1row.cl` file contains an OpenCL kernel for performing matrix-vector multiplication where the matrix is in half-precision (f16) and the vector is in single-precision (f32), optimized for different GPU architectures.
- **[mul_mv_f16_f32_l4.cl](kernels/mul_mv_f16_f32_l4.cl.driver.md)**: The `mul_mv_f16_f32_l4.cl` file in the `llama.cpp` codebase contains an OpenCL kernel for performing matrix-vector multiplication using half-precision and single-precision floating-point numbers, with optimizations for different GPU architectures.
- **[mul_mv_f32_f32.cl](kernels/mul_mv_f32_f32.cl.driver.md)**: The `mul_mv_f32_f32.cl` file in the `llama.cpp` codebase contains an OpenCL kernel for performing matrix-vector multiplication with support for different GPU architectures and subgroup sizes.
- **[mul_mv_q4_0_f32.cl](kernels/mul_mv_q4_0_f32.cl.driver.md)**: The `mul_mv_q4_0_f32.cl` file contains an OpenCL kernel implementation for performing matrix-vector multiplication using quantized blocks and floating-point operations, optimized for different GPU architectures.
- **[mul_mv_q4_0_f32_1d_16x_flat.cl](kernels/mul_mv_q4_0_f32_1d_16x_flat.cl.driver.md)**: The `mul_mv_q4_0_f32_1d_16x_flat.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for performing matrix-vector multiplication with specific optimizations for different GPU architectures, using 1D blocking and 16x output.
- **[mul_mv_q4_0_f32_1d_8x_flat.cl](kernels/mul_mv_q4_0_f32_1d_8x_flat.cl.driver.md)**: The `mul_mv_q4_0_f32_1d_8x_flat.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for performing matrix-vector multiplication with specific optimizations for different GPU architectures, using 1D blocking and 8x output.
- **[mul_mv_q4_0_f32_8x_flat.cl](kernels/mul_mv_q4_0_f32_8x_flat.cl.driver.md)**: The `mul_mv_q4_0_f32_8x_flat.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for performing matrix-vector multiplication using quantized data and specific optimizations for Intel and Adreno GPUs.
- **[mul_mv_q4_0_f32_v.cl](kernels/mul_mv_q4_0_f32_v.cl.driver.md)**: The `mul_mv_q4_0_f32_v.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for performing matrix-vector multiplication optimized for different GPU architectures, including Intel and Adreno, using quantized data formats.
- **[mul_mv_q6_k.cl](kernels/mul_mv_q6_k.cl.driver.md)**: The `mul_mv_q6_k.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for performing matrix-vector multiplication using 6-bit quantization, optimized for different GPU architectures.
- **[norm.cl](kernels/norm.cl.driver.md)**: The `norm.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for normalizing data by computing the mean and variance, and then scaling the data accordingly.
- **[pad.cl](kernels/pad.cl.driver.md)**: The `pad.cl` file contains an OpenCL kernel function that pads a source array with zeros when copying it to a destination array, based on specified dimensions.
- **[relu.cl](kernels/relu.cl.driver.md)**: The `relu.cl` file contains an OpenCL kernel implementation of the ReLU activation function, which processes input data and outputs the result by applying the ReLU operation.
- **[repeat.cl](kernels/repeat.cl.driver.md)**: The `repeat.cl` file in the `llama.cpp` codebase contains an OpenCL kernel function that performs data repetition or broadcasting from a source to a destination buffer across multiple dimensions.
- **[rms_norm.cl](kernels/rms_norm.cl.driver.md)**: The `rms_norm.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for RMS normalization, optimized for different GPU architectures using subgroup sizes.
- **[rope.cl](kernels/rope.cl.driver.md)**: The `rope.cl` file in the `llama.cpp` codebase contains OpenCL kernels implementing the YaRN algorithm for scaled rotary embeddings, supporting both single and half precision floating-point operations for various data processing tasks.
- **[scale.cl](kernels/scale.cl.driver.md)**: The `scale.cl` file contains an OpenCL kernel function that scales elements of a float4 array by a given factor.
- **[sigmoid.cl](kernels/sigmoid.cl.driver.md)**: The `sigmoid.cl` file contains OpenCL kernels for computing the sigmoid function on both 32-bit and 16-bit floating point data.
- **[silu.cl](kernels/silu.cl.driver.md)**: The `silu.cl` file in the `llama.cpp` codebase contains OpenCL kernels for computing the SiLU (Sigmoid Linear Unit) activation function on both single float and float4 data types.
- **[softmax_4_f16.cl](kernels/softmax_4_f16.cl.driver.md)**: The `softmax_4_f16.cl` file in the `llama.cpp` codebase contains an OpenCL kernel implementation for computing the softmax function on 4-element vectors of half-precision floating-point numbers, with support for various GPU architectures and subgroup sizes.
- **[softmax_4_f32.cl](kernels/softmax_4_f32.cl.driver.md)**: The `softmax_4_f32.cl` file in the `llama.cpp` codebase implements an OpenCL kernel for computing the softmax function on 4-element float vectors, with support for various GPU architectures and subgroup sizes.
- **[softmax_f16.cl](kernels/softmax_f16.cl.driver.md)**: The `softmax_f16.cl` file in the `llama.cpp` codebase implements an OpenCL kernel for computing the softmax function on half-precision floating-point data, with support for various GPU architectures and optimizations for parallel execution.
- **[softmax_f32.cl](kernels/softmax_f32.cl.driver.md)**: The `softmax_f32.cl` file in the `llama.cpp` codebase implements an OpenCL kernel for computing the softmax function on floating-point data, with support for various GPU architectures and optimizations for subgroup operations.
- **[sub.cl](kernels/sub.cl.driver.md)**: The `sub.cl` file in the `llama.cpp` codebase contains OpenCL kernels for performing element-wise subtraction operations on arrays, including a specialized kernel for subtracting a row from a matrix.
- **[sum_rows.cl](kernels/sum_rows.cl.driver.md)**: The `sum_rows.cl` file contains an OpenCL kernel function that computes the sum of each row in a 4D array and stores the result in a destination array.
- **[tanh.cl](kernels/tanh.cl.driver.md)**: The `tanh.cl` file in the `llama.cpp` codebase provides OpenCL kernel implementations for computing the hyperbolic tangent function on both 32-bit and 16-bit floating-point tensors, with support for specific GPU subgroup sizes.
- **[transpose.cl](kernels/transpose.cl.driver.md)**: The `transpose.cl` file in the `llama.cpp` codebase contains OpenCL kernels for performing 16-bit and 32-bit matrix transpositions, including a specialized kernel for 32-bit to 16-bit conversion with zero padding for non-multiple of 8 prompt lengths.
- **[tsembd.cl](kernels/tsembd.cl.driver.md)**: The `tsembd.cl` file contains an OpenCL kernel function for computing timestep embeddings using cosine and sine functions based on input timesteps and frequency calculations.
- **[upscale.cl](kernels/upscale.cl.driver.md)**: The `upscale.cl` file in the `llama.cpp` codebase contains OpenCL kernels for performing image upscaling, including both nearest-neighbor and bilinear interpolation methods.
