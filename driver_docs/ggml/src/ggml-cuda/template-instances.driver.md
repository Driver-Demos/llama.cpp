
## Files
- **[fattn-mma-f16-instance-ncols1_1-ncols2_16.cu](template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_16.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_1-ncols2_16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for matrix multiplication with half-precision floating-point numbers.
- **[fattn-mma-f16-instance-ncols1_1-ncols2_8.cu](template-instances/fattn-mma-f16-instance-ncols1_1-ncols2_8.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_1-ncols2_8.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters for matrix multiplication operations.
- **[fattn-mma-f16-instance-ncols1_16-ncols2_1.cu](template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_1.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_16-ncols2_1.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters.
- **[fattn-mma-f16-instance-ncols1_16-ncols2_2.cu](template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_2.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_16-ncols2_2.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of the `fattn-mma-f16` template with specific matrix dimensions.
- **[fattn-mma-f16-instance-ncols1_16-ncols2_4.cu](template-instances/fattn-mma-f16-instance-ncols1_16-ncols2_4.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_16-ncols2_4.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters.
- **[fattn-mma-f16-instance-ncols1_2-ncols2_16.cu](template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_16.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_2-ncols2_16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for matrix multiplication with half-precision floating-point numbers.
- **[fattn-mma-f16-instance-ncols1_2-ncols2_4.cu](template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_4.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_2-ncols2_4.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters.
- **[fattn-mma-f16-instance-ncols1_2-ncols2_8.cu](template-instances/fattn-mma-f16-instance-ncols1_2-ncols2_8.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_2-ncols2_8.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of the `fattn-mma-f16` template with specific matrix dimensions.
- **[fattn-mma-f16-instance-ncols1_32-ncols2_1.cu](template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_1.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_32-ncols2_1.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters for matrix multiplication operations.
- **[fattn-mma-f16-instance-ncols1_32-ncols2_2.cu](template-instances/fattn-mma-f16-instance-ncols1_32-ncols2_2.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_32-ncols2_2.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters for matrix multiplication operations.
- **[fattn-mma-f16-instance-ncols1_4-ncols2_16.cu](template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_16.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_4-ncols2_16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for matrix multiplication with half-precision floating-point numbers.
- **[fattn-mma-f16-instance-ncols1_4-ncols2_2.cu](template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_2.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_4-ncols2_2.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of the `fattn-mma-f16` template with specific matrix dimensions and column configurations.
- **[fattn-mma-f16-instance-ncols1_4-ncols2_4.cu](template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_4.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_4-ncols2_4.cu` file is an autogenerated CUDA source file that declares multiple instances of the `fattn-mma-f16` template with specific matrix dimensions.
- **[fattn-mma-f16-instance-ncols1_4-ncols2_8.cu](template-instances/fattn-mma-f16-instance-ncols1_4-ncols2_8.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_4-ncols2_8.cu` file is an autogenerated CUDA source file that declares multiple instances of the `fattn-mma-f16` template with specific matrix dimensions.
- **[fattn-mma-f16-instance-ncols1_64-ncols2_1.cu](template-instances/fattn-mma-f16-instance-ncols1_64-ncols2_1.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_64-ncols2_1.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters for matrix multiplication operations.
- **[fattn-mma-f16-instance-ncols1_8-ncols2_1.cu](template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_1.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_8-ncols2_1.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters for matrix multiplication operations.
- **[fattn-mma-f16-instance-ncols1_8-ncols2_2.cu](template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_2.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_8-ncols2_2.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying parameters for matrix multiplication operations.
- **[fattn-mma-f16-instance-ncols1_8-ncols2_4.cu](template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_4.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_8-ncols2_4.cu` file in the `llama.cpp` codebase is an autogenerated CUDA source file that declares multiple instances of a function template for matrix multiplication with specific dimensions and half-precision floating-point format.
- **[fattn-mma-f16-instance-ncols1_8-ncols2_8.cu](template-instances/fattn-mma-f16-instance-ncols1_8-ncols2_8.cu.driver.md)**: The `fattn-mma-f16-instance-ncols1_8-ncols2_8.cu` file is an autogenerated CUDA source file that declares multiple instances of the `DECL_FATTN_MMA_F16_CASE` macro with varying matrix dimensions.
- **[fattn-vec-f16-instance-hs128-f16-f16.cu](template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-f16-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with half-precision floating-point types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-f16-q4_0.cu](template-instances/fattn-vec-f16-instance-hs128-f16-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-f16-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with half-precision floating-point and quantized types.
- **[fattn-vec-f16-instance-hs128-f16-q4_1.cu](template-instances/fattn-vec-f16-instance-hs128-f16-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-f16-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-f16-q5_0.cu](template-instances/fattn-vec-f16-instance-hs128-f16-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-f16-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for handling 128-element vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-f16-q5_1.cu](template-instances/fattn-vec-f16-instance-hs128-f16-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-f16-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-f16-q8_0.cu](template-instances/fattn-vec-f16-instance-hs128-f16-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-f16-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with half-precision floating-point and quantized types.
- **[fattn-vec-f16-instance-hs128-q4_0-f16.cu](template-instances/fattn-vec-f16-instance-hs128-q4_0-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_0-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling vectorized attention operations with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_0-q4_0.cu](template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_0-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-dimensional vector attention using half-precision floating-point and Q4_0 data types.
- **[fattn-vec-f16-instance-hs128-q4_0-q4_1.cu](template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_0-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantization types Q4_0 and Q4_1.
- **[fattn-vec-f16-instance-hs128-q4_0-q5_0.cu](template-instances/fattn-vec-f16-instance-hs128-q4_0-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_0-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_0-q5_1.cu](template-instances/fattn-vec-f16-instance-hs128-q4_0-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_0-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_0-q8_0.cu](template-instances/fattn-vec-f16-instance-hs128-q4_0-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_0-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_1-f16.cu](template-instances/fattn-vec-f16-instance-hs128-q4_1-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_1-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with types `GGML_TYPE_Q4_1` and `GGML_TYPE_F16`.
- **[fattn-vec-f16-instance-hs128-q4_1-q4_0.cu](template-instances/fattn-vec-f16-instance-hs128-q4_1-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_1-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantization types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_1-q4_1.cu](template-instances/fattn-vec-f16-instance-hs128-q4_1-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_1-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-dimensional vectors with types `GGML_TYPE_Q4_1` in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_1-q5_0.cu](template-instances/fattn-vec-f16-instance-hs128-q4_1-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_1-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q4_1-q5_1.cu](template-instances/fattn-vec-f16-instance-hs128-q4_1-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_1-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling attention vectors with half-precision floating-point numbers and quantization types Q4_1 and Q5_1.
- **[fattn-vec-f16-instance-hs128-q4_1-q8_0.cu](template-instances/fattn-vec-f16-instance-hs128-q4_1-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q4_1-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_0-f16.cu](template-instances/fattn-vec-f16-instance-hs128-q5_0-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_0-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_0-q4_0.cu](template-instances/fattn-vec-f16-instance-hs128-q5_0-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_0-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers and quantization types Q5_0 and Q4_0.
- **[fattn-vec-f16-instance-hs128-q5_0-q4_1.cu](template-instances/fattn-vec-f16-instance-hs128-q5_0-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_0-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_0-q5_0.cu](template-instances/fattn-vec-f16-instance-hs128-q5_0-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_0-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_0-q5_1.cu](template-instances/fattn-vec-f16-instance-hs128-q5_0-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_0-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantization types Q5_0 and Q5_1.
- **[fattn-vec-f16-instance-hs128-q5_0-q8_0.cu](template-instances/fattn-vec-f16-instance-hs128-q5_0-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_0-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_1-f16.cu](template-instances/fattn-vec-f16-instance-hs128-q5_1-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_1-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling vectorized attention operations with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_1-q4_0.cu](template-instances/fattn-vec-f16-instance-hs128-q5_1-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_1-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_1-q4_1.cu](template-instances/fattn-vec-f16-instance-hs128-q5_1-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_1-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling vectorized attention operations with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_1-q5_0.cu](template-instances/fattn-vec-f16-instance-hs128-q5_1-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_1-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_1-q5_1.cu](template-instances/fattn-vec-f16-instance-hs128-q5_1-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_1-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 16-bit floating-point vector attention with specific types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q5_1-q8_0.cu](template-instances/fattn-vec-f16-instance-hs128-q5_1-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q5_1-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q8_0-f16.cu](template-instances/fattn-vec-f16-instance-hs128-q8_0-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q8_0-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling vectorized attention operations with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q8_0-q4_0.cu](template-instances/fattn-vec-f16-instance-hs128-q8_0-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q8_0-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q8_0-q4_1.cu](template-instances/fattn-vec-f16-instance-hs128-q8_0-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q8_0-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers and quantization types Q8_0 and Q4_1.
- **[fattn-vec-f16-instance-hs128-q8_0-q5_0.cu](template-instances/fattn-vec-f16-instance-hs128-q8_0-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q8_0-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and quantized types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q8_0-q5_1.cu](template-instances/fattn-vec-f16-instance-hs128-q8_0-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q8_0-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point numbers in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs128-q8_0-q8_0.cu](template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs128-q8_0-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with half-precision floating-point and Q8_0 data types.
- **[fattn-vec-f16-instance-hs256-f16-f16.cu](template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs256-f16-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 256-element vectors with half-precision floating-point types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs64-f16-f16.cu](template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.driver.md)**: The `fattn-vec-f16-instance-hs64-f16-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for 16-bit floating-point attention vectors with a head size of 64.
- **[fattn-vec-f16-instance-hs64-f16-q4_0.cu](template-instances/fattn-vec-f16-instance-hs64-f16-q4_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs64-f16-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 64-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f16-instance-hs64-f16-q4_1.cu](template-instances/fattn-vec-f16-instance-hs64-f16-q4_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs64-f16-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 64-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f16-instance-hs64-f16-q5_0.cu](template-instances/fattn-vec-f16-instance-hs64-f16-q5_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs64-f16-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 16-bit floating-point and Q5_0 types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs64-f16-q5_1.cu](template-instances/fattn-vec-f16-instance-hs64-f16-q5_1.cu.driver.md)**: The `fattn-vec-f16-instance-hs64-f16-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 16-bit floating-point and Q5_1 types in the `llama.cpp` codebase.
- **[fattn-vec-f16-instance-hs64-f16-q8_0.cu](template-instances/fattn-vec-f16-instance-hs64-f16-q8_0.cu.driver.md)**: The `fattn-vec-f16-instance-hs64-f16-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 16-bit floating-point and Q8_0 types.
- **[fattn-vec-f32-instance-hs128-f16-f16.cu](template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-f16-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for 128-element vector attention using half-precision floating-point types.
- **[fattn-vec-f32-instance-hs128-f16-q4_0.cu](template-instances/fattn-vec-f32-instance-hs128-f16-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-f16-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs128-f16-q4_1.cu](template-instances/fattn-vec-f32-instance-hs128-f16-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-f16-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-dimensional vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs128-f16-q5_0.cu](template-instances/fattn-vec-f32-instance-hs128-f16-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-f16-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vectors with half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs128-f16-q5_1.cu](template-instances/fattn-vec-f32-instance-hs128-f16-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-f16-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs128-f16-q8_0.cu](template-instances/fattn-vec-f32-instance-hs128-f16-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-f16-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vector attention using half-precision floating-point and quantized 8-bit types.
- **[fattn-vec-f32-instance-hs128-q4_0-f16.cu](template-instances/fattn-vec-f32-instance-hs128-q4_0-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_0-f16.cu` file is an autogenerated CUDA source file that declares a specific instantiation of a function for handling 128-element vectors with types `GGML_TYPE_Q4_0` and `GGML_TYPE_F16`.
- **[fattn-vec-f32-instance-hs128-q4_0-q4_0.cu](template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_0-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for 128-element vector attention using the `GGML_TYPE_Q4_0` data type.
- **[fattn-vec-f32-instance-hs128-q4_0-q4_1.cu](template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_0-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vector attention with types `GGML_TYPE_Q4_0` and `GGML_TYPE_Q4_1`.
- **[fattn-vec-f32-instance-hs128-q4_0-q5_0.cu](template-instances/fattn-vec-f32-instance-hs128-q4_0-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_0-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with types `GGML_TYPE_Q4_0` and `GGML_TYPE_Q5_0`.
- **[fattn-vec-f32-instance-hs128-q4_0-q5_1.cu](template-instances/fattn-vec-f32-instance-hs128-q4_0-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_0-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with types `GGML_TYPE_Q4_0` and `GGML_TYPE_Q5_1`.
- **[fattn-vec-f32-instance-hs128-q4_0-q8_0.cu](template-instances/fattn-vec-f32-instance-hs128-q4_0-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_0-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with 128 elements using types `GGML_TYPE_Q4_0` and `GGML_TYPE_Q8_0`.
- **[fattn-vec-f32-instance-hs128-q4_1-f16.cu](template-instances/fattn-vec-f32-instance-hs128-q4_1-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_1-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with types `GGML_TYPE_Q4_1` and `GGML_TYPE_F16`.
- **[fattn-vec-f32-instance-hs128-q4_1-q4_0.cu](template-instances/fattn-vec-f32-instance-hs128-q4_1-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_1-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instantiation of a function template for processing attention vectors with half-size 128 and types Q4_1 and Q4_0.
- **[fattn-vec-f32-instance-hs128-q4_1-q4_1.cu](template-instances/fattn-vec-f32-instance-hs128-q4_1-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_1-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-dimensional vector attention using the Q4_1 data type in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q4_1-q5_0.cu](template-instances/fattn-vec-f32-instance-hs128-q4_1-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_1-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with types `GGML_TYPE_Q4_1` and `GGML_TYPE_Q5_0`.
- **[fattn-vec-f32-instance-hs128-q4_1-q5_1.cu](template-instances/fattn-vec-f32-instance-hs128-q4_1-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_1-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with types `GGML_TYPE_Q4_1` and `GGML_TYPE_Q5_1`.
- **[fattn-vec-f32-instance-hs128-q4_1-q8_0.cu](template-instances/fattn-vec-f32-instance-hs128-q4_1-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q4_1-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with specific data types in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q5_0-f16.cu](template-instances/fattn-vec-f32-instance-hs128-q5_0-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_0-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vector attention using Q5_0 and F16 data types.
- **[fattn-vec-f32-instance-hs128-q5_0-q4_0.cu](template-instances/fattn-vec-f32-instance-hs128-q5_0-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_0-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for floating-point attention vectors with specific types and dimensions in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q5_0-q4_1.cu](template-instances/fattn-vec-f32-instance-hs128-q5_0-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_0-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a floating-point attention vector case with parameters 128, GGML_TYPE_Q5_0, and GGML_TYPE_Q4_1.
- **[fattn-vec-f32-instance-hs128-q5_0-q5_0.cu](template-instances/fattn-vec-f32-instance-hs128-q5_0-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_0-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vector attention with quantization type Q5_0 in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q5_0-q5_1.cu](template-instances/fattn-vec-f32-instance-hs128-q5_0-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_0-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 128-element vector attention with types `GGML_TYPE_Q5_0` and `GGML_TYPE_Q5_1`.
- **[fattn-vec-f32-instance-hs128-q5_0-q8_0.cu](template-instances/fattn-vec-f32-instance-hs128-q5_0-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_0-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a floating-point attention vector case with parameters 128, GGML_TYPE_Q5_0, and GGML_TYPE_Q8_0.
- **[fattn-vec-f32-instance-hs128-q5_1-f16.cu](template-instances/fattn-vec-f32-instance-hs128-q5_1-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_1-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vectors with types `GGML_TYPE_Q5_1` and `GGML_TYPE_F16`.
- **[fattn-vec-f32-instance-hs128-q5_1-q4_0.cu](template-instances/fattn-vec-f32-instance-hs128-q5_1-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_1-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for floating-point attention vectors with specific types and dimensions.
- **[fattn-vec-f32-instance-hs128-q5_1-q4_1.cu](template-instances/fattn-vec-f32-instance-hs128-q5_1-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_1-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for floating-point attention vectors with specific types and dimensions.
- **[fattn-vec-f32-instance-hs128-q5_1-q5_0.cu](template-instances/fattn-vec-f32-instance-hs128-q5_1-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_1-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with specific data types in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q5_1-q5_1.cu](template-instances/fattn-vec-f32-instance-hs128-q5_1-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_1-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vector attention with Q5_1 data types in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q5_1-q8_0.cu](template-instances/fattn-vec-f32-instance-hs128-q5_1-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q5_1-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with parameters 128, GGML_TYPE_Q5_1, and GGML_TYPE_Q8_0.
- **[fattn-vec-f32-instance-hs128-q8_0-f16.cu](template-instances/fattn-vec-f32-instance-hs128-q8_0-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q8_0-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with specific data types in the `llama.cpp` codebase.
- **[fattn-vec-f32-instance-hs128-q8_0-q4_0.cu](template-instances/fattn-vec-f32-instance-hs128-q8_0-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q8_0-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vector attention with types `GGML_TYPE_Q8_0` and `GGML_TYPE_Q4_0`.
- **[fattn-vec-f32-instance-hs128-q8_0-q4_1.cu](template-instances/fattn-vec-f32-instance-hs128-q8_0-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q8_0-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for processing attention vectors with specified types and dimensions.
- **[fattn-vec-f32-instance-hs128-q8_0-q5_0.cu](template-instances/fattn-vec-f32-instance-hs128-q8_0-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q8_0-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 128-element vector attention with types `GGML_TYPE_Q8_0` and `GGML_TYPE_Q5_0`.
- **[fattn-vec-f32-instance-hs128-q8_0-q5_1.cu](template-instances/fattn-vec-f32-instance-hs128-q8_0-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q8_0-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for floating-point attention vectors with specified types and dimensions.
- **[fattn-vec-f32-instance-hs128-q8_0-q8_0.cu](template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs128-q8_0-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for 128-element vector attention with Q8_0 data types.
- **[fattn-vec-f32-instance-hs256-f16-f16.cu](template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs256-f16-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function for handling 256-element vector attention with half-precision floating-point types.
- **[fattn-vec-f32-instance-hs64-f16-f16.cu](template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.driver.md)**: The `fattn-vec-f32-instance-hs64-f16-f16.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 64-element vector attention with half-precision floating-point types.
- **[fattn-vec-f32-instance-hs64-f16-q4_0.cu](template-instances/fattn-vec-f32-instance-hs64-f16-q4_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs64-f16-q4_0.cu` file is an autogenerated CUDA source file that declares a specific instantiation of a function for 64-element vectors using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs64-f16-q4_1.cu](template-instances/fattn-vec-f32-instance-hs64-f16-q4_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs64-f16-q4_1.cu` file is an autogenerated CUDA source file that declares a specific instantiation of a function template for 64-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs64-f16-q5_0.cu](template-instances/fattn-vec-f32-instance-hs64-f16-q5_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs64-f16-q5_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 64-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs64-f16-q5_1.cu](template-instances/fattn-vec-f32-instance-hs64-f16-q5_1.cu.driver.md)**: The `fattn-vec-f32-instance-hs64-f16-q5_1.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 64-element vector attention using half-precision floating-point and quantized types.
- **[fattn-vec-f32-instance-hs64-f16-q8_0.cu](template-instances/fattn-vec-f32-instance-hs64-f16-q8_0.cu.driver.md)**: The `fattn-vec-f32-instance-hs64-f16-q8_0.cu` file is an autogenerated CUDA source file that declares a specific instance of a function template for 64-element vector attention using half-precision floating-point and quantized 8-bit types.
- **[generate_cu_files.py](template-instances/generate_cu_files.py.driver.md)**: The `generate_cu_files.py` file in the `llama.cpp` codebase is a script that generates CUDA source files for various quantization types and configurations by creating instances of attention vector and matrix multiplication operations.
- **[mmq-instance-iq1_s.cu](template-instances/mmq-instance-iq1_s.cu.driver.md)**: The `mmq-instance-iq1_s.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific MMQ case for the `GGML_TYPE_IQ1_S` type.
- **[mmq-instance-iq2_s.cu](template-instances/mmq-instance-iq2_s.cu.driver.md)**: The `mmq-instance-iq2_s.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific MMQ case for the `GGML_TYPE_IQ2_S` type.
- **[mmq-instance-iq2_xs.cu](template-instances/mmq-instance-iq2_xs.cu.driver.md)**: The `mmq-instance-iq2_xs.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_IQ2_XS` type using the `DECL_MMQ_CASE` macro.
- **[mmq-instance-iq2_xxs.cu](template-instances/mmq-instance-iq2_xxs.cu.driver.md)**: The `mmq-instance-iq2_xxs.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_IQ2_XXS` type using the `DECL_MMQ_CASE` macro.
- **[mmq-instance-iq3_s.cu](template-instances/mmq-instance-iq3_s.cu.driver.md)**: The `mmq-instance-iq3_s.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific MMQ case for the `GGML_TYPE_IQ3_S` type.
- **[mmq-instance-iq3_xxs.cu](template-instances/mmq-instance-iq3_xxs.cu.driver.md)**: The `mmq-instance-iq3_xxs.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_IQ3_XXS` type using the `DECL_MMQ_CASE` macro.
- **[mmq-instance-iq4_nl.cu](template-instances/mmq-instance-iq4_nl.cu.driver.md)**: The `mmq-instance-iq4_nl.cu` file is an autogenerated CUDA source file that declares a specific MMQ case for the `GGML_TYPE_IQ4_NL` type.
- **[mmq-instance-iq4_xs.cu](template-instances/mmq-instance-iq4_xs.cu.driver.md)**: The `mmq-instance-iq4_xs.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_IQ4_XS` type using the `DECL_MMQ_CASE` macro.
- **[mmq-instance-q2_k.cu](template-instances/mmq-instance-q2_k.cu.driver.md)**: The `mmq-instance-q2_k.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific case for `GGML_TYPE_Q2_K`.
- **[mmq-instance-q3_k.cu](template-instances/mmq-instance-q3_k.cu.driver.md)**: The `mmq-instance-q3_k.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_Q3_K` type using the `mmq.cuh` header.
- **[mmq-instance-q4_0.cu](template-instances/mmq-instance-q4_0.cu.driver.md)**: The `mmq-instance-q4_0.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_Q4_0` type using the `mmq.cuh` header.
- **[mmq-instance-q4_1.cu](template-instances/mmq-instance-q4_1.cu.driver.md)**: The `mmq-instance-q4_1.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_Q4_1` type using the `DECL_MMQ_CASE` macro.
- **[mmq-instance-q4_k.cu](template-instances/mmq-instance-q4_k.cu.driver.md)**: The `mmq-instance-q4_k.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific case for `GGML_TYPE_Q4_K`.
- **[mmq-instance-q5_0.cu](template-instances/mmq-instance-q5_0.cu.driver.md)**: The `mmq-instance-q5_0.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific MMQ case for `GGML_TYPE_Q5_0`.
- **[mmq-instance-q5_1.cu](template-instances/mmq-instance-q5_1.cu.driver.md)**: The `mmq-instance-q5_1.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific MMQ case for `GGML_TYPE_Q5_1`.
- **[mmq-instance-q5_k.cu](template-instances/mmq-instance-q5_k.cu.driver.md)**: The `mmq-instance-q5_k.cu` file is an autogenerated CUDA source file that includes the `mmq.cuh` header and declares a specific MMQ case for the `GGML_TYPE_Q5_K` type.
- **[mmq-instance-q6_k.cu](template-instances/mmq-instance-q6_k.cu.driver.md)**: The `mmq-instance-q6_k.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_Q6_K` type using the `DECL_MMQ_CASE` macro.
- **[mmq-instance-q8_0.cu](template-instances/mmq-instance-q8_0.cu.driver.md)**: The `mmq-instance-q8_0.cu` file is an autogenerated CUDA source file that declares a specific case for the `GGML_TYPE_Q8_0` type using the `mmq.cuh` header.
