## Folders
- **[batched-bench](tools/batched-bench.driver.md)**: The `batched-bench` folder in the `llama.cpp` codebase contains tools and documentation for benchmarking the batched decoding performance of a language model, including a C++ source file for the benchmarking tool, a CMake configuration file for building the executable, and a README with usage instructions and examples.
- **[cvector-generator](tools/cvector-generator.driver.md)**: The `cvector-generator` folder in the `llama.cpp` codebase contains files for building and implementing a tool that generates control vectors from text prompts, utilizing techniques like PCA and mean calculation, and includes configuration, documentation, and sample data for testing.
- **[export-lora](tools/export-lora.driver.md)**: The `export-lora` folder in the `llama.cpp` codebase contains files for configuring, implementing, and documenting the process of merging a base model with LoRA adapters and exporting the result as a GGUF file.
- **[gguf-split](tools/gguf-split.driver.md)**: The `gguf-split` folder in the `llama.cpp` codebase contains files for building, executing, and testing a tool that splits and merges GGUF files, including a CMake configuration, source code, usage instructions, and a test script.
- **[imatrix](tools/imatrix.driver.md)**: The `imatrix` folder in the `llama.cpp` codebase contains files for configuring, implementing, and documenting the process of computing an importance matrix to enhance quantized model quality.
- **[llama-bench](tools/llama-bench.driver.md)**: The `llama-bench` folder in the `llama.cpp` codebase contains files for configuring, implementing, and documenting a benchmarking tool designed to evaluate the performance of the LLaMA model with support for various output formats.
- **[main](tools/main.driver.md)**: The `main` folder in the `llama.cpp` codebase contains essential files for building and running a text generation or chat application using the LLaMA model, including configuration, source code, and usage instructions.
- **[mtmd](tools/mtmd.driver.md)**: The `mtmd` folder in the `llama.cpp` codebase contains a collection of files and a subfolder dedicated to implementing and testing multimodal support, including image and audio processing, with tools for handling CLIP models, audio preprocessing, and a command-line interface, as well as a `legacy-models` folder for processing older model formats.
- **[perplexity](tools/perplexity.driver.md)**: The `perplexity` folder in the `llama.cpp` codebase contains files for building and using a tool to evaluate language models by calculating perplexity and other metrics, with configuration, implementation, and usage documentation provided.
- **[quantize](tools/quantize.driver.md)**: The `quantize` folder in the `llama.cpp` codebase contains files for configuring, implementing, documenting, and testing the quantization process of machine learning models, including a CMake configuration file, a C++ source file for quantization functionality, a README for instructions, and a shell script for testing.
- **[rpc](tools/rpc.driver.md)**: The `rpc` folder in the `llama.cpp` codebase contains files for configuring, documenting, and implementing an RPC server to enable distributed LLM inference using the `ggml` backend.
- **[run](tools/run.driver.md)**: The `run` folder in the `llama.cpp` codebase contains resources for building and executing the `llama-run` command-line tool, including a CMake configuration file, a README with usage instructions, and a source file for running language models, along with a folder for a line editing library.
- **[server](tools/server.driver.md)**: The `server` folder in the `llama.cpp` codebase contains a comprehensive setup for a server environment, including scripts and configurations for server benchmarks, web interfaces for chat applications, unit tests, themes, and a React-based web UI, along with essential server implementation files and documentation.
- **[tokenize](tools/tokenize.driver.md)**: The `tokenize` folder in the `llama.cpp` codebase contains the build configuration and implementation files for a command-line tool designed to tokenize text prompts using a specified model.
- **[tts](tools/tts.driver.md)**: The `tts` folder in the `llama.cpp` codebase contains files for configuring, converting, and executing a text-to-speech system using OuteAI models, including build configuration, model conversion scripts, and tools for generating audio from text.

## Files
- **[CMakeLists.txt](tools/CMakeLists.txt.driver.md)**: The `CMakeLists.txt` file in `llama.cpp/tools` configures the build process for various tools and dependencies, including conditional subdirectory additions based on build options like `EMSCRIPTEN`, `LLAMA_BUILD_SERVER`, and `GGML_RPC`.
