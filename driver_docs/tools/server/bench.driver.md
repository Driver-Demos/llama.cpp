
## Files
- **[bench.py](bench/bench.py.driver.md)**: The `bench.py` file in the `llama.cpp` codebase is a script designed to start a server benchmark scenario, execute performance tests, and collect metrics for analysis and visualization.
- **[prometheus.yml](bench/prometheus.yml.driver.md)**: The `prometheus.yml` file configures Prometheus to scrape metrics from the `llama.cpp` server every 10 seconds, targeting `localhost:8080`.
- **[README.md](bench/README.md.driver.md)**: The `README.md` file in the `llama.cpp/tools/server/bench` directory provides instructions for setting up and running server benchmark tools using k6, including installation, dataset and model downloading, server configuration, benchmark execution, and metrics analysis.
- **[requirements.txt](bench/requirements.txt.driver.md)**: The `requirements.txt` file in the `llama.cpp` codebase specifies `matplotlib` and `requests` as dependencies for the project.
- **[script.js](bench/script.js.driver.md)**: The `script.js` file in the `llama.cpp` codebase is a benchmarking script for testing server chat completions, utilizing the k6 tool to measure performance metrics such as token processing rates and completion success rates.
