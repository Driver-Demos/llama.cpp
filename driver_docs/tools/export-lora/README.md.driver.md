# Purpose
The provided content is a documentation snippet for a command-line tool named `llama-export-lora`, which is used to apply Low-Rank Adaptation (LORA) adapters to a base machine learning model and export the modified model. The tool allows users to specify the path to the base model using the `--model` option and apply one or more LORA adapters through the `--lora` or `--lora-scaled` options, the latter allowing for user-defined scaling of the adapter's influence. Users can also define the number of computation threads with the `--threads` option and specify the output file name with the `--output` option. The examples demonstrate how to execute the tool with various configurations, including applying multiple LORA adapters simultaneously, showcasing its flexibility in model adaptation tasks.
