
## Files
- **[gemma3.md](multimodal/gemma3.md.driver.md)**: The `gemma3.md` file provides instructions for setting up and running the experimental Gemma 3 vision model in the `llama.cpp` codebase, including building the project, converting models, and executing the multimodal demo.
- **[glmedge.md](multimodal/glmedge.md.driver.md)**: The `glmedge.md` file provides instructions for using and converting GLMV-EDGE models, specifically glm-edge-v-2b and glm-edge-v-5b, within the `llama.cpp` project.
- **[granitevision.md](multimodal/granitevision.md.driver.md)**: The `granitevision.md` file provides detailed instructions for setting up and running the Granite Vision model, including downloading the model, running scripts for model surgery, creating visual and language model components, converting them to GGUF format, and running the model in the `llama.cpp` environment.
- **[llava.md](multimodal/llava.md.driver.md)**: The `llava.md` file in the `llama.cpp` codebase provides detailed instructions for using and converting LLaVA models, specifically versions 1.5 and 1.6, including setup, conversion to GGUF format, and running the models with the `llama-mtmd-cli` tool.
- **[minicpmo2.6.md](multimodal/minicpmo2.6.md.driver.md)**: The `minicpmo2.6.md` file provides instructions for preparing and using the MiniCPM-o 2.6 model with llama.cpp, including model conversion and inference steps.
- **[minicpmv2.5.md](multimodal/minicpmv2.5.md.driver.md)**: The `minicpmv2.5.md` file provides instructions for preparing, building, and using the MiniCPM-Llama3-V 2.5 model within the `llama.cpp` framework, including steps for model conversion and inference.
- **[minicpmv2.6.md](multimodal/minicpmv2.6.md.driver.md)**: The `minicpmv2.6.md` file provides instructions for preparing, building, and using the MiniCPM-V 2.6 model with the llama.cpp framework, including steps for model conversion and inference.
- **[MobileVLM.md](multimodal/MobileVLM.md.driver.md)**: The `MobileVLM.md` file provides documentation for the implementation and usage of the MobileVLM-1.7B and MobileVLM_V2-1.7B models, including instructions for model conversion, compilation, and running on various platforms such as Android, Orin, and Intel processors.
