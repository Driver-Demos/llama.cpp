# Purpose
The provided content is a documentation snippet for configuring and utilizing the GLMV-EDGE models, specifically the glm-edge-v-2b and glm-edge-v-5b, which are hosted on Hugging Face. It outlines the steps to build and execute the `llama-mtmd-cli` binary, which is used to interact with these models, and provides command-line examples for running the binary with specific model paths and parameters. The document also details the process of converting GLMV-EDGE models into the GGUF format, which involves cloning the model repository, using Python scripts to split the model into its components, and converting these components into the GGUF format. This conversion is necessary for preparing the models for specific use cases, such as image encoding and language model processing, ensuring they are stored in the designated `model_path` directory.
