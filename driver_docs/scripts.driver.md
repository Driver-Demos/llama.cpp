## Folders
- **[apple](scripts/apple.driver.md)**: The `apple` folder in the `llama.cpp` codebase contains a collection of shell scripts for validating applications across various Apple platforms, including iOS, macOS, visionOS, and tvOS, ensuring they are correctly built and embedded with the `llama.xcframework`.

## Files
- **[build-info.sh](scripts/build-info.sh.driver.md)**: The `build-info.sh` file in the `llama.cpp` codebase generates build information including the build number, commit hash, compiler version, and target architecture.
- **[check-requirements.sh](scripts/check-requirements.sh.driver.md)**: The `check-requirements.sh` file in the `llama.cpp` codebase is a Bash script that verifies the requirements for each top-level Python conversion script by setting up a virtual environment, installing dependencies, and checking for import errors.
- **[ci-run.sh](scripts/ci-run.sh.driver.md)**: The `ci-run.sh` file is a script in the `llama.cpp` codebase that wraps the execution of `ci/run.sh`, managing temporary and cache directories to optimize disk usage and syncing model and data files.
- **[compare-commits.sh](scripts/compare-commits.sh.driver.md)**: The `compare-commits.sh` file is a Bash script used to compare the performance of two Git commits in the `llama.cpp` codebase by running benchmarks and generating results using the `compare-llama-bench.py` script.
- **[compare-llama-bench.py](scripts/compare-llama-bench.py.driver.md)**: The `compare-llama-bench.py` file in the `llama.cpp` codebase is a script that compares performance data from multiple runs of the `llama-bench` tool, using data from JSON, CSV, or SQLite files, and outputs the results in a tabulated format.
- **[debug-test.sh](scripts/debug-test.sh.driver.md)**: The `debug-test.sh` file is a Bash script designed to facilitate debugging of specific ctest programs in the `llama.cpp` codebase by setting up a build environment, compiling test binaries, and optionally running tests in gdb mode.
- **[fetch_server_test_models.py](scripts/fetch_server_test_models.py.driver.md)**: The `fetch_server_test_models.py` file is a script designed to fetch all models used in server tests to prevent timeouts during downloads, by parsing test files for model parameters and using a command-line interface to ensure the models are fetched.
- **[gen-authors.sh](scripts/gen-authors.sh.driver.md)**: The `gen-authors.sh` file is a Bash script that generates an `AUTHORS` file by listing unique contributors from the Git log of the `master` branch, with an option to update specific names.
- **[gen-unicode-data.py](scripts/gen-unicode-data.py.driver.md)**: The `gen-unicode-data.py` file in the `llama.cpp` codebase generates C++ source code for Unicode data handling, including codepoint flags, whitespace, lowercase and uppercase mappings, and NFD normalization ranges, by processing data from the Unicode Consortium.
- **[get-flags.mk](scripts/get-flags.mk.driver.md)**: The `get-flags.mk` file in the `llama.cpp` codebase determines the compiler type and version, setting appropriate flags for either GCC or Clang compilers.
- **[get-hellaswag.sh](scripts/get-hellaswag.sh.driver.md)**: The `get-hellaswag.sh` file is a script that downloads the `hellaswag_val_full.txt` file and provides usage instructions for running a perplexity test with the `llama-perplexity` tool.
- **[get-pg.sh](scripts/get-pg.sh.driver.md)**: The `get-pg.sh` file is a Bash script that downloads a specified number of essays from a given RSS feed, processes them into text format, and compiles them into a `pg.txt` file.
- **[get-wikitext-103.sh](scripts/get-wikitext-103.sh.driver.md)**: The `get-wikitext-103.sh` file is a script that downloads the Wikitext-103 dataset and provides usage instructions for running a perplexity test with a specified model.
- **[get-wikitext-2.sh](scripts/get-wikitext-2.sh.driver.md)**: The `get-wikitext-2.sh` file is a script that downloads and unzips the Wikitext-2 dataset, and provides usage instructions for running a perplexity test with a specified model.
- **[get-winogrande.sh](scripts/get-winogrande.sh.driver.md)**: The `get-winogrande.sh` file is a script that downloads the Winogrande debiased evaluation dataset and provides usage instructions for evaluating it with the `llama-perplexity` tool.
- **[get_chat_template.py](scripts/get_chat_template.py.driver.md)**: The `get_chat_template.py` file in the `llama.cpp` codebase is a script that retrieves the Jinja chat template for a specified HuggingFace model, allowing for optional specification of a template variant.
- **[hf.sh](scripts/hf.sh.driver.md)**: The `hf.sh` file in the `llama.cpp` codebase is a Bash script that provides a shortcut for downloading models from Hugging Face using either `curl` or `wget`.
- **[install-oneapi.bat](scripts/install-oneapi.bat.driver.md)**: The `install-oneapi.bat` file is a batch script for downloading and installing Intel's oneAPI components, with options for specifying components and logging, in the `llama.cpp` codebase.
- **[qnt-all.sh](scripts/qnt-all.sh.driver.md)**: The `qnt-all.sh` file is a Bash script that automates the quantization of a specified model using various quantization levels, saving the results to a designated output directory.
- **[run-all-perf.sh](scripts/run-all-perf.sh.driver.md)**: The `run-all-perf.sh` file is a bash script in the `llama.cpp` codebase that runs performance benchmarks for different quantization levels on a specified model.
- **[run-all-ppl.sh](scripts/run-all-ppl.sh.driver.md)**: The `run-all-ppl.sh` file is a Bash script in the `llama.cpp` codebase that runs a perplexity test on a specified model using various quantization levels and outputs the results to a designated directory.
- **[sync-ggml-am.sh](scripts/sync-ggml-am.sh.driver.md)**: The `sync-ggml-am.sh` file is a bash script used to synchronize changes from the `ggml` repository to the `llama.cpp` project, allowing for the exclusion of specific commits and setting the context for git patches.
- **[sync-ggml.sh](scripts/sync-ggml.sh.driver.md)**: The `sync-ggml.sh` file is a bash script used to synchronize various files and directories from the `ggml` directory to the corresponding locations within the `llama.cpp` project.
- **[sync_vendor.py](scripts/sync_vendor.py.driver.md)**: The `sync_vendor.py` file in the `llama.cpp` codebase is a script that downloads and updates specific vendor files from various URLs to designated paths in the local directory.
- **[tool_bench.py](scripts/tool_bench.py.driver.md)**: The `tool_bench.py` file in the `llama.cpp` codebase provides a script for benchmarking tool calls on llama-server and ollama by running tests multiple times at various temperatures and backends, and visualizing the results as a success rate heatmap.
- **[tool_bench.sh](scripts/tool_bench.sh.driver.md)**: The `tool_bench.sh` file is a Bash script in the `llama.cpp` codebase that builds the project, sets environment variables, and runs a series of benchmarking tests on various models using the `tool_bench.py` script, outputting results in JSONL format and generating plots from these results.
- **[verify-checksum-models.py](scripts/verify-checksum-models.py.driver.md)**: The `verify-checksum-models.py` file in the `llama.cpp` codebase verifies the integrity of model files by comparing their SHA256 checksums against a list of expected hashes.
- **[xxd.cmake](scripts/xxd.cmake.driver.md)**: The `xxd.cmake` file in the `llama.cpp` codebase provides a CMake script to convert a specified input file into a C-style header file with hexadecimal data representation.
